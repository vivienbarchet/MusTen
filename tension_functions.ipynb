{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be229f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import librosa.display\n",
    "import librosa\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Audio\n",
    "from scipy.ndimage.filters import uniform_filter1d\n",
    "\n",
    "\n",
    "\n",
    "import dissonant\n",
    "import os\n",
    "import scipy\n",
    "import pandas as pd\n",
    "\n",
    "import import_ipynb\n",
    "from scipy import stats\n",
    "import spleeter\n",
    "\n",
    "from pydub import AudioSegment\n",
    "import soundfile\n",
    "from scipy.signal import savgol_filter\n",
    "from scipy import signal\n",
    "import scipy.signal\n",
    "from matplotlib.lines import Line2D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3254f0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Only_features.ipynb     #defining our custom functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b574b4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def music_loading(file_name, path, sr = 44100):\n",
    "    #Enter file name and (relative) path\n",
    "    audio_fpath = path + file_name + '.wav'\n",
    "    print(audio_fpath)\n",
    "\n",
    "    # load audio file\n",
    "    y, sr = librosa.load(audio_fpath, sr = 44100)\n",
    "\n",
    "    ###Trimming should be done in the very beginning (cut out silent parts)\n",
    "    y, index = librosa.effects.trim(y=y, frame_length=sr, top_db=60)\n",
    "\n",
    "    trimmed_audio_path = path + file_name + \"_trim\" + '.wav'\n",
    "    soundfile.write(trimmed_audio_path, y, sr)\n",
    "\n",
    "    return y,sr, trimmed_audio_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7dfcb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extraction(y,sr, trimmed_audio_path, category = \"polyphonic\",  start_bpm = 80):\n",
    "    #Features \n",
    "\n",
    "    #Tempo\n",
    "    [tempo, t_tempo] = tempo_extraction(y,sr, start_bpm = start_bpm)\n",
    "\n",
    "    #Onset\n",
    "    [onset_env, onset_freq, t_onset] = onset_frequency(y,sr)\n",
    "\n",
    "    #Loudness\n",
    "    [loudness, t_loudness] = extract_loudness(y,sr)\n",
    "\n",
    "    #pitches\n",
    "    pitch_df = pitch_extraction(trimmed_audio_path,sr,category = \"polyphonic\")\n",
    "\n",
    "    #Dissonance\n",
    "    [dissonance, t_dissonance] = dissonance_extraction(pitch_df, sr)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #Tempo & Loudness\n",
    "    df_tup = list(zip(t_tempo, tempo, loudness[0]))\n",
    "    df_tempo_loudness= pd.DataFrame(df_tup, columns = [\"time\", \"tempo\", \"loudness\"])\n",
    "\n",
    "    df_tempo_loudness['tempo_z'] = stats.zscore(df_tempo_loudness['tempo'])\n",
    "    df_tempo_loudness['loudness_z'] = stats.zscore(df_tempo_loudness['loudness'])\n",
    "\n",
    "    \n",
    "    #Pitch \n",
    "\n",
    "    #Integrating melody and bass to use all pitches for standardization\n",
    "    df_long = pd.melt(pitch_df, id_vars='time')\n",
    "    df_long[\"pitch_z\"] = (df_long.value - df_long.value.mean())/df_long.value.std(ddof=0)\n",
    "\n",
    "    #Separating the pitches again \n",
    "    #So now, we have the two pitch lines but standardized on the basis of the two lines together\n",
    "    df_wide_pitch_z = df_long.pivot(index='time', columns='variable', values='pitch_z')\n",
    "    df_wide_pitch_z = df_wide_pitch_z.reset_index()\n",
    "\n",
    "    #Merging pitch with tempo and loudness\n",
    "    df_loudness_tempo_pitch = pd.merge(df_wide_pitch_z, df_tempo_loudness.iloc[:,[0,3,4]], on = \"time\", how = \"left\")\n",
    "\n",
    "    \n",
    "    #Dissonance\n",
    "    df_tup = zip(t_dissonance, dissonance)\n",
    "    df_dissonance= pd.DataFrame(df_tup, columns = [\"time\", \"dissonance\"])\n",
    "    df_dissonance = df_dissonance.dropna()\n",
    "    df_dissonance['dissonance_z'] = stats.zscore(df_dissonance['dissonance'])\n",
    "    \n",
    "    #Onset frequency\n",
    "    df_tup = list(zip(t_onset, onset_freq))\n",
    "    df_onset_freq= pd.DataFrame(df_tup, columns = [\"time\", \"onset_freq\"])\n",
    "\n",
    "    df_onset_freq['onset_freq_z'] = stats.zscore(df_onset_freq['onset_freq'])\n",
    "\n",
    "    ## Merging --\n",
    "    #Onset frequency\n",
    "    merge_onset = pd.merge(df_loudness_tempo_pitch,df_onset_freq.iloc[:,[0,2]],on='time', how='left')\n",
    "\n",
    "    merge_onset.loc[pd.notnull(merge_onset.onset_freq_z)]\n",
    "    \n",
    "    #Dissonance\n",
    "    df_all_features = pd.merge(merge_onset, df_dissonance.iloc[:,[0,2]], on = \"time\", how = 'left')\n",
    "\n",
    "    df_all_features.loc[pd.notnull(df_all_features.dissonance_z)]\n",
    "    ##Padding nas for plotting\n",
    "    df_plot = df_all_features.fillna(method='ffill')\n",
    "\n",
    "    return df_all_features, df_plot, pitch_df, onset_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9cfd6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_features(df_plot,color_list):\n",
    "    plt.figure(figsize=(20, 8))\n",
    "\n",
    "    ##rearranging the columns\n",
    "    cols = df_plot.columns.tolist()\n",
    "    cols = [cols[0]]+ cols[-4:] + cols[1:-4]\n",
    "    df_plot = df_plot[cols]  \n",
    "\n",
    "    count = 0\n",
    "    custom_lines = []\n",
    "    feature_list = []\n",
    "    for f in df_plot.columns[1:]:\n",
    "        plt.plot(df_plot.time, df_plot[f], color = color_list[count])\n",
    "        custom_lines.append(Line2D([0], [0], color = color_list[count], lw = 3))\n",
    "        feature_list.append(f)\n",
    "        count = count + 1\n",
    "\n",
    "\n",
    "    plt.legend(custom_lines, feature_list , \n",
    "               loc='right', bbox_to_anchor=(1.2, 0.37), fancybox=True, facecolor='white', framealpha=1, \n",
    "              edgecolor = \"black\", fontsize = 20)\n",
    "\n",
    "    plt.title(\"All Features over Time\", fontsize = 30)\n",
    "    plt.ylabel(\"Z-Scores\", fontsize = 20)\n",
    "    plt.xlabel(\"Time (s)\", fontsize = 20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0fb599",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_smoothing(df_plot):\n",
    "\n",
    "\n",
    "    smooth_features = []\n",
    "    for f in df_plot.columns[1:]:\n",
    "        feature = df_plot[f].fillna(0)\n",
    "        feature_smooth = uniform_filter1d(feature, size =int(len(y)/30)) \n",
    "        smooth_features.append(feature_smooth)\n",
    "\n",
    "    dict_smooth = dict(zip(df_plot.columns[1:], smooth_features))\n",
    "\n",
    "    features_smooth = pd.DataFrame(dict_smooth)\n",
    "    features_smooth['time'] = df_plot['time']\n",
    "\n",
    "    #plt.figure(figsize=(20, 8))\n",
    "    #count = 0\n",
    "    #for f in features_smooth.columns[:-1]:\n",
    "\n",
    "     #   plt.plot(features_smooth.time, features_smooth[f], color = color_list[count])\n",
    "      #  count = count+1\n",
    "\n",
    "    #plt.title(\"All Features over Time\")\n",
    "    #plt.ylabel(\"Z-Scores\")\n",
    "    #plt.xlabel(\"Time (s)\")\n",
    "    \n",
    "    return features_smooth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c81cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_resampling_10Hz(features_smooth, df_plot):\n",
    "    sr_features = len(features_smooth)/max(features_smooth['time'])\n",
    "\n",
    "    all_features_10Hz = features_smooth.iloc[::int(sr_features/10)]\n",
    "    all_features_10Hz = all_features_10Hz.reset_index()\n",
    "\n",
    "    all_features_10Hz_unsmoothed = df_plot.iloc[::int(sr_features/10)]\n",
    "    all_features_10Hz_unsmoothed = all_features_10Hz_unsmoothed.reset_index()\n",
    "    \n",
    "    return all_features_10Hz, all_features_10Hz_unsmoothed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b146d75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tension_extraction_10Hz_window(all_features_10Hz, model_configuration = ['optimized', 'original']):\n",
    "    \n",
    "    ##add the actual optimized values\n",
    "    if model_configuration == 'optimized':\n",
    "        attentional_windows = {'dissonance':1, 'tempo':1, 'loudness':1, 'pitch':1, 'onset_freq':1}\n",
    "        memory_windows = {'dissonance':1, 'tempo':1, 'loudness':1, 'pitch':1, 'onset_freq':1}\n",
    "        global_integration_window = 2\n",
    "\n",
    "    elif model_configuration == 'original':\n",
    "        attentional_windows = {'dissonance':8.5, 'tempo':2, 'loudness':2, 'pitch':2, 'onset_freq':1}\n",
    "        memory_windows= {'dissonance':13, 'tempo':2, 'loudness':0, 'pitch':2, 'onset_freq':1}\n",
    "        global_integration_window = 1\n",
    "        \n",
    "    # get the exact sampling rate for our features: \n",
    "    sr_features = len(all_features_10Hz)/max(all_features_10Hz['time'])\n",
    "\n",
    "    #Calculate the shift (0.25 s recommended)\n",
    "    shift = round(0.25 * sr_features)\n",
    "    if shift == 0:\n",
    "        shift = 1\n",
    "\n",
    "    #Could potentially be optimized? \n",
    "    prevSlope = 0.5\n",
    "\n",
    "    feature = []\n",
    "    window = []\n",
    "    slopes_m = []\n",
    "    times = []\n",
    "\n",
    "    pitch_col = [col for col in all_features_10Hz if col.startswith('line')]\n",
    "    pitch_num = len(pitch_col)\n",
    "\n",
    "    #Loop through all columns except for time (i.e. the features)\n",
    "    for i in range(0,len(all_features_10Hz), shift):\n",
    "        slopes = []\n",
    "        for f in all_features_10Hz.columns[4:]:\n",
    "            if f == \"dissonance_z\":\n",
    "                attention_window = attentional_windows['dissonance']\n",
    "                memory_window = memory_windows['dissonance']\n",
    "\n",
    "            elif f == \"tempo_z\":\n",
    "                attention_window = attentional_windows['tempo']\n",
    "                memory_window = memory_windows['tempo']\n",
    "                    \n",
    "            elif f == \"loudness_z\":\n",
    "                attention_window = attentional_windows['loudness']\n",
    "                memory_window = memory_windows['loudness']\n",
    "                \n",
    "            elif f == \"pitch\":\n",
    "                attention_window = attentional_windows['pitch']\n",
    "                memory_window = memory_windows['pitch']\n",
    "                    \n",
    "            elif f.startswith(\"line\"):\n",
    "                attention_window = attentional_windows['pitch']\n",
    "                memory_window = memory_windows['pitch']\n",
    "                    \n",
    "            elif f == \"onset_freq_z\":\n",
    "                attention_window = attentional_windows['onset_freq']\n",
    "                memory_window = memory_windows['onset_freq']\n",
    "\n",
    "\n",
    "            n_samp_m = int(memory_window*round(sr_features))\n",
    "            n_samp_a = int(attention_window*round(sr_features))\n",
    "\n",
    "        \n",
    "            #get start and end points for attentional window\n",
    "            start_a = i\n",
    "            end_a = n_samp_a + i\n",
    "            x_a = list(range(0,n_samp_a))\n",
    "\n",
    "            #End: attentional window is shorter\n",
    "            if (len(all_features_10Hz) - end_a) < 0:\n",
    "                end_a = len(all_features_10Hz) \n",
    "                x_a = range(0,(end_a - start_a))\n",
    "\n",
    "            #and for the memory window (if there is one)\n",
    "            if memory_window > 0:\n",
    "                end_m = start_a - 1\n",
    "                start_m = end_m - n_samp_m\n",
    "\n",
    "                if start_m < 1:\n",
    "                    start_m = 0\n",
    "                    x_m = list(range(0,end_m))\n",
    "                else:\n",
    "                    x_m = list(range(0,n_samp_m))\n",
    "\n",
    "\n",
    "                curr_mem = end_m - start_m +1\n",
    "                \n",
    "                if i > 2: # need at least 2 points for memory window\n",
    "                    memoryWindowActive = True\n",
    "                else:\n",
    "                    memoryWindowActive = False\n",
    "\n",
    "            #get the current attentional window\n",
    "            curr_win = all_features_10Hz[f].iloc[start_a:end_a]\n",
    "            if len(curr_win) > 1:\n",
    "                slope = np.polyfit(x_a, curr_win, 1)\n",
    "                slope = slope[0]\n",
    "                feature.append(f)\n",
    "                \n",
    "\n",
    "                if f.startswith('line'):\n",
    "                    slope = slope*(1/pitch_num)\n",
    "                    \n",
    "            if memory_window > 0 and memoryWindowActive == True:\n",
    "\n",
    "                curr_win_m = all_features_10Hz[f].iloc[start_m:end_m]\n",
    "\n",
    "                    \n",
    "                slope_m = np.polyfit(x_m,curr_win_m,1)\n",
    "                prevSlope = slope_m[0]\n",
    "\n",
    "                slopes_m.append(prevSlope)\n",
    "\n",
    "\n",
    "            epsilon = .0001;\n",
    "            decay = .001;\n",
    "\n",
    "            if (memory_window > 0) and memoryWindowActive:\n",
    "            # If there is no change in attentional slope (practically\n",
    "            # speaking) following no change in the memory window, add a\n",
    "            # decrease the slope of the attentional window slightly.\n",
    "                if (slope < epsilon) and (slope > -epsilon) and (prevSlope < epsilon) and (prevSlope > -epsilon):\n",
    "                    slope = slope - decay;\n",
    "                # if both attentional and memory windows are in the same\n",
    "                # direction, negative or positive, strengthen the attentional\n",
    "                # window slope in the current direction\n",
    "                elif ((slope > 0) and (prevSlope > 0)) or ((slope < 0) and (prevSlope < 0)):\n",
    "                    # 5 = recommendation\n",
    "                    slope = slope * 5\n",
    "\n",
    "            slopes.append(slope)\n",
    "        \n",
    "        \n",
    "        overall_slope = sum(slopes)\n",
    "\n",
    "        attention_window = global_integration_window\n",
    "            \n",
    "        n_samp_a = int(attention_window*round(sr_features))\n",
    "\n",
    "        start_a = i\n",
    "        #get start and end points for attentional window\n",
    "\n",
    "        end_a = n_samp_a + i\n",
    "        x_a = list(range(1,n_samp_a+1))\n",
    "\n",
    "        #End: attentional window is shorter\n",
    "        if (len(all_features_10Hz) - end_a) < 0:\n",
    "            end_a = len(all_features_10Hz) \n",
    "            x_a = range(1,(end_a - start_a+1))\n",
    "\n",
    "\n",
    "        cur_slope = overall_slope*np.array(x_a)\n",
    "\n",
    "        if start_a < (len(all_features_10Hz)-1):\n",
    "            if start_a == 0:\n",
    "                prediction = cur_slope\n",
    "\n",
    "            else:\n",
    "                start = prediction[0:start_a]\n",
    "                startval = prediction[start_a]\n",
    "                middle = np.array(cur_slope[0:(len(prediction)-(start_a))]+prediction[(start_a):])/2\n",
    "\n",
    "                if middle.size!=0:\n",
    "                    offset1 = startval - middle[0]\n",
    "                    middle = middle + offset1\n",
    "\n",
    "                endChunk = cur_slope[len(middle)+1:]\n",
    "\n",
    "                if middle.size!=0 & endChunk.size!=0:\n",
    "                    offset2 = middle[-1] - endChunk[0]\n",
    "                    endChunk = endChunk + offset2\n",
    "\n",
    "                if endChunk.size!=0:\n",
    "                    prediction = list(start) + list(middle) + list(endChunk)\n",
    "                else:\n",
    "                    prediction = list(start) + list(middle)\n",
    "\n",
    "\n",
    "    prediction = stats.zscore(prediction)\n",
    "\n",
    "    df_slopes = pd.DataFrame(zip(all_features_10Hz['time'], prediction), columns = ['time', 'prediction'])\n",
    "    \n",
    "\n",
    "    return df_slopes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fae4b6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_tension_and_features_10Hz(df_slopes, all_features_10Hz_unsmoothed, color_list):\n",
    "    plt.figure(figsize = [20,8])\n",
    "    \n",
    "    custom_lines = []\n",
    "    feature_list = []\n",
    "    count = 0\n",
    "    \n",
    "    cols = all_features_10Hz_unsmoothed.columns.tolist()\n",
    "    cols_reorder = cols[0:2] + cols[-4:] + cols[2:-4]\n",
    "    all_features_plot = all_features_10Hz_unsmoothed[cols_reorder]  \n",
    "\n",
    "    for f in all_features_plot.columns[2:]:\n",
    "        plt.plot(all_features_plot.time, all_features_plot[f], color = color_list[count])\n",
    "        count = count+1\n",
    "        custom_lines.append(Line2D([0], [0], color = color_list[count], lw = 3))\n",
    "        feature_list.append(f)\n",
    "        \n",
    "    plt.plot(df_slopes['time'], df_slopes['prediction'], color = \"black\", fillstyle='none',\n",
    "               marker = \"s\", markerfacecolor = \"black\", linestyle = \"none\", markersize = 6)\n",
    "\n",
    "    plt.plot(df_slopes['time'], df_slopes['prediction'], color = \"black\", \n",
    "             linewidth = 3, alpha = 1)\n",
    "    \n",
    "\n",
    "\n",
    "    plt.legend(custom_lines, feature_list , \n",
    "               loc='right', bbox_to_anchor=(1.2, 0.37), fancybox=True, facecolor='white', framealpha=1, \n",
    "              edgecolor = \"black\", fontsize = 20)\n",
    "\n",
    "    plt.title(\"All Features and the Tension Prediction over Time\", fontsize = 30)\n",
    "    plt.ylabel(\"Z-Scores\", fontsize = 20)\n",
    "    plt.xlabel(\"Time (s)\", fontsize = 20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84c4cbc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tension_extraction_10Hz_weights(all_features_10Hz, model_configuration = ['optimized', 'original']):\n",
    "    \n",
    "    if model_configuration == 'optimized':\n",
    "        weights_dict = {'dissonance':2, 'tempo':1, 'loudness':7, 'pitch':8, 'onset_freq':1}\n",
    "        windows_dict = {'attention':3, 'memory':2}\n",
    "    \n",
    "    elif model_configuration == 'original':\n",
    "        weights_dict = {'dissonance':1, 'tempo':2, 'loudness':3, 'pitch':1, 'onset_freq':2}\n",
    "        windows_dict = {'attention':3, 'memory':3}\n",
    "        \n",
    "    #Get the weights for all columns\n",
    "    weights = []\n",
    "    pitch_col = [col for col in all_features_10Hz if col.startswith('line')]\n",
    "    pitch_num = len(pitch_col)\n",
    "    \n",
    "    for f in all_features_10Hz.columns[1:]:\n",
    "\n",
    "        if f == \"dissonance_z\":\n",
    "            weight = weights_dict['dissonance']\n",
    "            weights.append(weight)\n",
    "        elif f == \"tempo_z\":\n",
    "            weight = weights_dict['tempo']\n",
    "            weights.append(weight)\n",
    "        elif f == \"loudness_z\":\n",
    "            weight = weights_dict['loudness']\n",
    "            weights.append(weight)\n",
    "        #This is not optimal, because there may be different numbers of pitch cols \n",
    "        elif f == \"pitch\":\n",
    "            weight = weights_dict['pitch']\n",
    "            weights.append(weight)\n",
    "        elif f.startswith(\"line\"):\n",
    "            weight = weights_dict['pitch']/pitch_num\n",
    "            weights.append(weight)\n",
    "        elif f == \"onset_freq_z\":\n",
    "            weight = weights_dict['onset_freq']\n",
    "            weights.append(weight)\n",
    "\n",
    "\n",
    "        scale_weights = sum(weights)\n",
    "\n",
    "    weights = dict(zip(all_features_10Hz.columns[1:], weights))\n",
    "    \n",
    "    \n",
    "    # get the exact sampling rate for our features: \n",
    "    sr_features = len(all_features_10Hz)/max(all_features_10Hz['time'])\n",
    "\n",
    "    #Calculate the shift (0.25 s recommended)\n",
    "    shift = int(0.25*sr_features)\n",
    "\n",
    "    #Could potentially be optimized? \n",
    "    prevSlope = 0.5\n",
    "\n",
    "    feature = []\n",
    "    window = []\n",
    "    slopes_m = []\n",
    "    times = []\n",
    "\n",
    "    #Loop through all columns except for time (i.e. the features)\n",
    "\n",
    "    ##Calculating the sum of all weights first (number of features may differ because of the pitch extraction)\n",
    "    \n",
    "    #fixed window durations\n",
    "    attention_window = windows_dict['attention']\n",
    "    memory_window = windows_dict['memory']\n",
    "\n",
    "    n_samp_m = int(memory_window*round(sr_features))\n",
    "    n_samp_a = int(attention_window*round(sr_features))\n",
    "\n",
    "    for i in range(0,len(all_features_10Hz), shift):\n",
    "        slopes_weighted = []\n",
    "        #get start and end points for attentional window\n",
    "        start_a = i\n",
    "        end_a = n_samp_a + i\n",
    "        x_a = list(range(0,n_samp_a))\n",
    "\n",
    "        #End: attentional window is shorter\n",
    "        if (len(all_features_10Hz) - end_a) < 0:\n",
    "            end_a = len(all_features_10Hz) \n",
    "            x_a = range(0,(end_a - start_a))\n",
    "\n",
    "        #and for the memory window (if there is one)\n",
    "        if memory_window > 0:\n",
    "            end_m = start_a - 1\n",
    "            start_m = end_m - n_samp_m +1\n",
    "            if start_m < 0:\n",
    "                start_m = 0\n",
    "\n",
    "            curr_mem = end_m - start_m +1\n",
    "\n",
    "            x_m = list(range(0,curr_mem))\n",
    "\n",
    "            if i > 2: # need at least 2 points for memory window\n",
    "                memoryWindowActive = True\n",
    "            else:\n",
    "                memoryWindowActive = False\n",
    "\n",
    "        #get the current attentional window\n",
    "        curr_win = all_features_10Hz.iloc[start_a:end_a]\n",
    "        \n",
    "        for f in all_features_10Hz.columns[1:-1]:\n",
    "            weight_curr = weights[f]/scale_weights\n",
    "            \n",
    "            if len(curr_win) > 1:\n",
    "                slope = np.polyfit(x_a, curr_win[f], 1)\n",
    "                slope = slope[0]\n",
    "                slope_weighted = slope*weight_curr\n",
    "                feature.append(f)\n",
    "                slopes_weighted.append(slope_weighted)\n",
    "\n",
    "        if memory_window > 0 and memoryWindowActive == True:\n",
    "            curr_win_m = prediction[start_m:end_m+1]\n",
    "            slope_m = np.polyfit(x_m,curr_win_m,1)\n",
    "            prevSlope = slope_m[0]\n",
    "\n",
    "            slopes_m.append(prevSlope)\n",
    "        \n",
    "        overall_slope = sum(slopes_weighted)\n",
    "\n",
    "        epsilon = .0001;\n",
    "        decay = .001;\n",
    "\n",
    "        if (memory_window > 0) and memoryWindowActive:\n",
    "        # If there is no change in attentional slope (practically\n",
    "        # speaking) following no change in the memory window, add a\n",
    "        # decrease the slope of the attentional window slightly.\n",
    "            if (overall_slope < epsilon) and (overall_slope > -epsilon) and (prevSlope < epsilon) and (prevSlope > -epsilon):\n",
    "                overall_slope = overall_slope - decay;\n",
    "            # if both attentional and memory windows are in the same\n",
    "            # direction, negative or positive, strengthen the attentional\n",
    "            # window slope in the current direction\n",
    "            elif ((overall_slope > 0) and (prevSlope > 0)) or ((overall_slope < 0) and (prevSlope < 0)):\n",
    "                # 5 = recommendation\n",
    "                overall_slope = overall_slope * 5\n",
    "\n",
    "\n",
    "        cur_slope = overall_slope*np.array(x_a)\n",
    "\n",
    "        if start_a < (len(all_features_10Hz)-1):\n",
    "            if start_a == 0:\n",
    "                prediction = cur_slope\n",
    "\n",
    "            else:\n",
    "                start = prediction[0:start_a]\n",
    "                startval = prediction[start_a]\n",
    "                middle = np.array(cur_slope[0:(len(prediction)-(start_a))]+prediction[(start_a):])/2\n",
    "\n",
    "                if middle.size!=0:\n",
    "                    offset1 = startval - middle[0]\n",
    "                    middle = middle + offset1\n",
    "\n",
    "                endChunk = cur_slope[len(middle)+1:]\n",
    "\n",
    "                if middle.size!=0 & endChunk.size!=0:\n",
    "                    offset2 = middle[-1] - endChunk[0]\n",
    "                    endChunk = endChunk + offset2\n",
    "\n",
    "                if endChunk.size!=0:\n",
    "                    prediction = list(start) + list(middle) + list(endChunk)\n",
    "                else:\n",
    "                    prediction = list(start) + list(middle)\n",
    "\n",
    "    \n",
    "    prediction = stats.zscore(prediction)\n",
    "\n",
    "    df_slopes = pd.DataFrame(zip(all_features_10Hz['time'], prediction), columns = ['time', 'prediction'])\n",
    "    \n",
    "    return df_slopes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa8d77e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
